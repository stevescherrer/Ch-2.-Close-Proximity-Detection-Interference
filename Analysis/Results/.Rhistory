metadata_df = rbind(metadata_df, cbind(as.character(subset_metadata$datetime[1]), 'receiver_212m', subset_metadata$data[subset_metadata$description == 'Daily Pings on 69 kHz'], subset_metadata$data[subset_metadata$description == 'Daily Syncs on 69 kHz'], subset_metadata$data[subset_metadata$description == 'Daily Detections on A69-1601'], subset_metadata$data[subset_metadata$description == 'Daily Rejects on 69 kHz']))
## Subset metadata log for receiver receiver_50m and write to dataframe
subset_metadata = metadata_50m[metadata_50m$datetime == unique(metadata_50m$datetime)[i], ]
metadata_df = rbind(metadata_df, cbind(as.character(subset_metadata$datetime[1]), 'receiver_50m', subset_metadata$data[subset_metadata$description == 'Daily Pings on 69 kHz'], subset_metadata$data[subset_metadata$description == 'Daily Syncs on 69 kHz'], subset_metadata$data[subset_metadata$description == 'Daily Detections on A69-1601'], subset_metadata$data[subset_metadata$description == 'Daily Rejects on 69 kHz']))
}
colnames(metadata_df) = c('date', 'receiver', 'pings', 'syncs', 'detections', 'rejections')
## Adding the following metrics based on Simpfendorfer et al 2008: Code Detection Efficiency (cde), rejection coefficient (rc), noise quotient (nq)
metadata_df$cde = as.numeric(as.character(metadata_df$detections)) / as.numeric(as.character(metadata_df$syncs))
metadata_df$rc  = as.numeric(as.character(metadata_df$rejections)) / as.numeric(as.character(metadata_df$syncs))
metadata_df$nq  = as.numeric(as.character(metadata_df$pings)) - (as.numeric(as.character(metadata_df$syncs)) * 7)
#### Statistical Analysis - Comparing Daily Detection Metrics ----
### Comparing Code Detection Efficiency
## Shapiro Wilk Test of Code Detection Efficiency
shapiro.test(metadata_df$cde[metadata_df$receiver == 'receiver_212m'])
# p-value = 0.7799
shapiro.test(metadata_df$cde[metadata_df$receiver == 'receiver_50m'])
# p-value = 0.002853
## Paired Wilcoxon test for code detection efficiency metric for each receiver
wilcox.test(x = metadata_df$cde[metadata_df$receiver == 'receiver_212m'],
y = metadata_df$cde[metadata_df$receiver == 'receiver_50m'],
paired = TRUE)
# p-value = 0.03125
median(x = metadata_df$cde[metadata_df$receiver == 'receiver_212m'])
# 0.0865077
median(x = metadata_df$cde[metadata_df$receiver == 'receiver_50m'])
# 1
### Comparing Rejection Coefficient
## Shapiro Wilk Test of Rejection Coefficient
### NOTE: Commmented out as cannot shapiro.test when all values are the same. rejection coefficent is 0 for all hour bins, therefore throws error when sourced
# shapiro.test(metadata_df$rc[metadata_df$receiver == 'receiver_50m'])
# Rejection Coefficient = 0. Cannot do a shapiro test.
shapiro.test(metadata_df$rc[metadata_df$receiver == 'receiver_212m'])
# p-value = 0.9427
## Paired Wilcoxon test for rejection coefficient metric for each receiver.
wilcox.test(x = metadata_df$rc[metadata_df$receiver == 'receiver_212m'],
y = metadata_df$rc[metadata_df$receiver == 'receiver_50m'],
paired = TRUE)
# p-value = 0.03125
median(metadata_df$rc[metadata_df$receiver == 'receiver_212m'])
# 0.01375137
median(metadata_df$rc[metadata_df$receiver == 'receiver_50m'])
# 0.00
### Comparing Noise Quotient
## Shapiro Wilk Test of Noise Quotient
shapiro.test(metadata_df$nq[metadata_df$receiver == 'receiver_50m'])
# p-value = 0.002315
shapiro.test(metadata_df$nq[metadata_df$receiver == 'receiver_212m'])
# p-value = 0.25
## Paired wilcoxon test for noise quotient metric for each receiver
wilcox.test(x = metadata_df$nq[metadata_df$receiver == 'receiver_212m'],
y = metadata_df$nq[metadata_df$receiver == 'receiver_50m'],
paired = TRUE)
# p-value = 0.03125
median(metadata_df$nq[metadata_df$receiver == 'receiver_212m'])
# -13793.5
median(metadata_df$nq[metadata_df$receiver == 'receiver_50m'])
# 1356
#### Analysis Cleanup -----
### Saving workspace in results folderb
setwd(results_dir)
save.image(file = 'Depth Validation Test Results.R')
###### COMPONENT 3: Depth and Distance Validation Experiment ----
#### Loading In and Cleaning Data Files #############
setwd(data_dir)
### Loading Receiver Data
receiver_data = load_receiver(filename = 'DEPLOYMENT_RECOVERY_LOG.csv')
### Loading VUE data
vue_data = load_vemco(filename = 'VUE_Export_Depth_and_Distance_Validation_Experiment_June_2015.csv')
### Loading receiver metadata logs
metadata_receiver_60m = read.csv('VUE_Export_Rec_123739_metadata.csv')
metadata_receiver_508m = read.csv('VUE_Export_Rec_102199_metadata.csv')
### Cleaning Vue Data
## Assigning receiver SNs and tag IDs to respective conditions
receiver_60m = 123739 # serial number of receiver in 50 m depth
receiver_508m = 102199 # serial number of receiver in 212 m depth
tag_ids = c(46915, 46912, 46913)
## Removing detections prior to deployment (occurred durring set up on boat) and after equipment recovered
start_date = as.POSIXct('2015-05-24 19:12:25', tz = "HST")
end_date = as.POSIXct('2015-05-30 09:46:00', tz = 'HST')
vue_data = vue_data[which(vue_data$datetime >= start_date & vue_data$datetime < end_date), ]
## Removing detections from partial hour bins, aka hour equipment was deployed and hour it was recovered before first full hour of test
vue_data = vue_data[which(vue_data$datetime >= ceiling_date(min(vue_data$datetime), unit = "hour") &
vue_data$datetime <= floor_date(max(vue_data$datetime), unit = "hour")), ]
## How many total tag detections were there?
detections_all = dim(vue_data)[1]
# Total detections of all tags = 1699
## Removing detections of tags not associated with current experiment
vue_data = vue_data[vue_data$tag_id %in% tag_ids, ]
detections_experiment = dim(vue_data)[1]
# Total detections of experimental tags = 1669
## What was the percentage of tag detections from experiment tags
detections_experiment.percent = detections_experiment / detections_all * 100
# 98.23426 %
## What was the number of logged detections from other tags
detections_other = detections_all - detections_experiment
# Total detections from other tags =  30
detections_other.percent = detections_other / detections_all * 100
# 1.765745
#### Hourly Detection Data Analysis ----
### Creating a dataframe (detection_df_4), to store results binned by hour
## Separating data by tag, receiver, and hour bin
## First assign each datum to an date and hour bin
vue_data$hour_bin = floor_date(vue_data$datetime, unit = "hour")
## Then loop through combinations of date/hour, tag id, and receiver to get the number of detections from a tag at a receiver each hour
detection_df_4 = data.frame()
registerDoParallel(cores = n_cores)
detection_df_4 = foreach(b = c(1:length(unique(vue_data$hour_bin))), .combine = rbind) %:%
foreach(r = c(1:length(unique(vue_data$receiver))), .combine = rbind) %dopar%{
filtered = filter(vue_data, hour_bin == unique(vue_data$hour_bin)[b],
receiver == unique(vue_data$receiver)[r])
write_line = cbind(as.character(unique(vue_data$hour_bin))[b],
as.character(unique(vue_data$receiver))[r],
dim(filtered)[1])
return(write_line)
}
detection_df_4 = as.data.frame(detection_df_4)
colnames(detection_df_4) = c('hour_bin', 'receiver', 'detections')
detection_df_4$detections = as.numeric(as.character(detection_df_4$detections))
## Assigning distance condition based on receiver sn
detection_df_4$distance = NA
detection_df_4$distance[detection_df_4$receiver == receiver_60m] = '60 m'
detection_df_4$distance[detection_df_4$receiver == receiver_508m] = '512 m'
#### Statistical Analysis - Comparing Hourly Detections ----
### Hourly Receiver Comparison
## Shapiro Wilk test that distribution of each case are non-parametric (p-value)
shapiro.test(detection_df_4$detections[detection_df_4$distance == '60 m'])
# p = 0.00151, p < 0.05 reject null hypothesis that distribution is normal
# Conclusion: Distribution is not normal
shapiro.test(detection_df_4$detections[detection_df_4$distance == '512 m'])
# p < 4.738e-09, p < 0.05 reject null hypothesis that distribution is normal
# Conclusion: Distribution is not normal
## Wilcox test - Selected to compare two groups (60m and 500m) non-parametrically
wilcox.test(x = detection_df_4$detections[detection_df_4$distance == '60 m'],
y = detection_df_4$detections[detection_df_4$distance ==  '512 m'],
paired = TRUE)
# p-value < 2.2e-16 reject null hypothesis that difference between groups is zero
# Conclusion: The two receivers logged signifcantly different detections from one another
## Ratio for Mean hourly detection rates for 60m receiver and 512 m receiver
mean_detections_60m  = mean(detection_df_4$detections[detection_df_4$distance == '60 m'])
# 4.879699
mean_detections_508m = mean(detection_df_4$detections[detection_df_4$distance == '512 m'])
# 7.669173
mean_detections_508m/mean_detections_60m
# receiver at 508m has 1.571649 x as many detections as receiver in 60 m
## Number of hours where deeper receiver detection rates exceeds shallow receiver
total_hour_bins = length(unique(detection_df_4$hour_bin))
times_508m_exceeds_60m = 0
times_508m_equal_to_60m = 0
for(hour in unique(detection_df_4$hour_bin)){
subset_detection_df_4 = filter(detection_df_4, hour_bin == hour)
if(subset_detection_df_4$detections[subset_detection_df_4$distance == '512 m'] >
subset_detection_df_4$detections[subset_detection_df_4$distance == '60 m']){
times_508m_exceeds_60m = times_508m_exceeds_60m + 1
}else if(subset_detection_df_4$detections[subset_detection_df_4$distance == '512 m'] ==
subset_detection_df_4$detections[subset_detection_df_4$distance == '60 m']){
times_508m_equal_to_60m = times_508m_equal_to_60m + 1
}
}
times_508m_exceeds_60m
# 107
times_508m_equal_to_60m
# 9
#### Analysis Cleanup -----
### Saving workspace in results folder
setwd(results_dir)
save.image(file = 'Depth and Distance Validation Test Results.R')
###### COMPONENT 4: Multipath Confirmation - Tank Experiment ----
## Analysis Ideas
# Break up analysis into three groups.
# 1.	Control
# 2.	Multipath (CPDI Not Expexted)
# 3.	Multipath (CPDI Expected)
## Anna's helpful analysis ideas:
# 1. Create table Event (single event would be do, 2a, 150m, 15m)
# 2. Catagorize each event (control, multipath-no CPDI, multipath - CPDI)
# 3. Code by type (CPDI predicted vs. not predicted)
# 4. Detected - number of actual detections at receiver
# Flip to wide table
# columns -
# 1. Event
# 2. Type
# 3. Detected
# 6. Fit GLM (Detected ~ type + event, family = binomial)
#### Loading in and Cleaning Data Files ----
setwd(data_dir)
### Importing VR100 data
vr100_raw = read.csv(paste(data_dir, 'VR100_10320_D2016.07.15T20.49.23.csv', sep = ""))
### Importing VR2 data from VUE
vr2 = load_vemco(paste(data_dir, 'VUE_Export_CPDI_Tank_Test.csv', sep = ""))
### Importing meta data regarding when transmissions were sent recorded from Brendan's laptop durring experiment
condStoreDM = read.csv(paste(data_dir, 'condStoreDM.csv', sep = ""), header = FALSE)
condStoreDO = read.csv(paste(data_dir, 'condStoreDO.csv', sep = ""), header = FALSE)
### Creating vr100 datafame for manipulation
vr100 = vr100_raw
vr100$datetime = as.POSIXct(paste(vr100$Date, vr100$Time, sep = " "), format = "%Y-%m-%d %H:%M:%S", tz = "GMT")
attr(vr100$datetime, "tzone") <- "HST"
colnames(vr100) = c("date", "time", "chan", "freq", "type", "code_space", "tag_id", "serial_number", "data1", "units1", "slope1", "init1", "data2", "units2", "slope2", "int2", "signal_db", "gain_mode", "gain_db", "lat", "lon", "comment", "datetime")
# creating vr2 dataframe for manipulation
vr2$datetime = as.POSIXct(vr2$datetime, tz = "GMT")
attr(vr2$datetime, "tzone") <- "GMT"
vr2 = vr2[vr2$datetime >= as.POSIXct("2016-07-12 16:30:00"), ]
### Creating dataframes for direct and multipath conditions
colnames(condStoreDO) = c('pluse_train_time', 'tag_range', 'tag_depth', 'relative_arrival_time_0','case_number', 'sub_case_number')
colnames(condStoreDM)[1:3] = c('pluse_train_time', 'tag_range', 'tag_depth')
colnames(condStoreDM)[4:23] = paste('relative_arrival_time_', 0:19, sep = "")
colnames(condStoreDM)[24:25] = c('case_number', 'sub_case_number')
condStoreDO$dm = 'direct only' # designates whether multipath or not
condStoreDM$dm = 'multipath' # designates whether multipath or not
### Predicting whether multipaths produced CPDI effects
## DO conditions only have a direct signal, all should be detected by receivers. thus they are marked as control
condStoreDO$cpdi_type = 'Control'
## To determine if multipath signals cause CPDI, we compare the relative arrival times of the multipath signals to the blanking interval (0.260 seconds).
condStoreDM$cpdi_type = 'multipath_no_cpdi_predicted'
for(i in 1:dim(condStoreDM)[1]){
if(any(condStoreDM[i,4:23] != 0 & condStoreDM[i,4:23] > 0.260)){
condStoreDM$cpdi_type[i] = 'multipath_cpdi_predicted'
}
}
### Combining direct and multipath condition dataframes into a single dataframe
## condStoreDO to do this, condStoreDO needs to be padded out to be same size as DM. This meens adding 20 additional columns
condStoreDO = cbind(condStoreDO[ ,1:4], matrix(data = NA, nrow = dim(condStoreDO)[1], ncol = 19), condStoreDO[ ,5:8])
colnames(condStoreDO)[5:23] = paste('relative_arrival_time_', 1:19, sep = "")
## Combining dataframes
condition = data.frame(rbind(condStoreDO, condStoreDM)) # Combining into condition dataframe
## Converting matlab date nubmers to POSIX datetime objects
condition$datetime = datenum2posix(condition$pluse_train_time)
### Ordering dataframes by increasing time of detection
condition = condition[order(condition$datetime), ] # sorting by time
vr2 = vr2[sort.list(x = vr2$datetime, decreasing = FALSE), ]
vr100 = vr100[sort.list(x = vr100$datetime, decreasing = FALSE), ]
rownames(vr100) = NULL
rownames(vr2) = NULL
### Converting vr2$receiver and vr2$tag_id to numeric
vr2$receiver = as.numeric(levels(vr2$receiver)[vr2$receiver])
vr2$tag_id = as.numeric(levels(vr2$tag_id)[vr2$tag_id])
### Pulling in all syncs to see if there is major drift in receivers/vr100 clocks
vr100_syncs = vr100[which(vr100$tag_id == 36817), ]
vr2_syncs = vr2[which(vr2$tag_id == 36817), ]
sync_data = data.frame(rbind(cbind(as.character(vr100_syncs$datetime), vr100_syncs$tag_id, 'vr100', vr100_syncs$signal_db),
cbind(as.character(vr2_syncs$datetime), vr2_syncs$tag_id, vr2_syncs$receiver, NA)))
colnames(sync_data) = c("datetime", "tag_id", "receiver", "signal_db")
sync_data = sync_data[order(as.POSIXct(sync_data$datetime)), ]
### Removing tag detections prior to experiment day
remove_prior_dates = as.POSIXct("2016-07-12 10:31:0 HST")
vr2 = vr2[vr2$datetime >= remove_prior_dates, ]
vr100 = vr100[vr100$datetime >= remove_prior_dates, ]
### Checking sync tag detected same number of times
length(which(vr100$tag_id == 36817)) # 1
length(which(vr2$tag_id == 36817))   # 1
### Checking which receiver were part of experiment
unique(vr2$receiver)
# 129577
### Checking which tags were logged on receiver
unique(vr2$tag_id)
# 36814 36817 18266 47515
unique(vr100$tag_id)
# 18266 47515 36814 36817
### Separating two receivers
## For VR100
vr100 = vr100[max(which(vr100$tag_id == 36817)):dim(vr100)[1], ]
### Adjusting vr100 dates to sync with vr2 dates. Used test tag on VR100 and VR2 in the lab for one detection
# VR2 detected tag at "2016-03-16 00:14:16 GMT"
# VR100 detected tag at"2016-03-16 00:13:40 GMT"
## Time offset  between VR2 and VR100
vr2_vr100_time_diff = difftime(time1 = max(vr100$datetime[vr100$tag_id == 36817]),
time2 = min(vr2$datetime[vr2$tag_id == 36817]))
# Time difference of -1 secs
vr100$datetime = vr100$datetime - vr2_vr100_time_diff
all_data = data.frame(matrix(data = 0, nrow = dim(vr2)[1] + dim(vr100)[1], ncol = 4))
colnames(all_data) = c("datetime", "tag_id", "receiver", "signal_db")
all_data$datetime = c(vr2$datetime, vr100$datetime)
all_data$tag_id = c(vr2$tag_id, vr100$tag_id)
all_data$receiver = c(vr2$receiver, rep('vr100', dim(vr100)[1]))
all_data$signal_db = c(rep(NA, length(vr2$receiver)), vr100$signal_db)
## Ordering by time
all_data = all_data[order(all_data$datetime), ]
rownames(all_data) = NULL
all_data$diff_time = 0
for(i in 2:length(all_data$diff_time)){
all_data$diff_time[i] = difftime(all_data$datetime[i], all_data$datetime[i-1], units = 'secs')
}
all_data$exp = NA
## Determining where experiments begin and end
all_data$exp[all_data$tag_id == 36817] = 'Sync'
all_data = all_data[all_data$datetime >= min(all_data$datetime[all_data$tag_id == 18266]), ]
## How many detections did each receiver log?
print(paste('Receiver 129577 detected', dim(all_data[which(all_data$receiver == 129577 & all_data$tag_id != 18266), ])[1], 'transmissions', sep = " "))
# Receiver 129577 detected 594 transmissions"
print(paste('The VR100 detected', dim(all_data[all_data$receiver == 'vr100', ])[1], 'transmissions', sep = " "))
# The VR100 detected 929 transmissions
### Matching conditions to recorded detection data (all_data)
rownames(all_data) = NULL
all_data$tag_range = NA
all_data$tag_depth = NA
all_data$case_number = NA
all_data$sub_case_number = NA
all_data$dm = NA
all_data$cpdi_type = NA
all_data$datetime = all_data$datetime - 6 # Adjusted this by comparing when the first test started ~18:58 on all data to first transmission sent in condition
for(i in 1:length(all_data$datetime)){
for(r in 1:length(condition$datetime)){
# If a detection occurred within an 8 second window
if(all_data$datetime[i] - 4 <= condition$datetime[r] & all_data$datetime[i] + 4 >= condition$datetime[r]){
all_data$tag_range[i] = condition$tag_range[r]
all_data$tag_depth[i] = condition$tag_depth[r]
all_data$case_number[i] = condition$case_number[r]
all_data$sub_case_number[i] = condition$sub_case_number[r]
all_data$dm[i] = condition$dm[r]
all_data$cpdi_type[i] = condition$cpdi_type[r]
}
}
}
## Changing all_data$sub_case_number from an integer to a character to match other formats
all_data$sub_case_number = as.character(all_data$sub_case_number)
all_data$sub_case_number[all_data$sub_case_number == '1'] = 'a'
all_data$sub_case_number[all_data$sub_case_number == '2'] = 'b'
all_data$sub_case_number[all_data$sub_case_number == '3'] = 'c'
all_data$sub_case_number[all_data$sub_case_number == '0'] = ''
all_data$exp = paste(all_data$dm, all_data$case_number, all_data$sub_case_number, sep = "")
### Creating a new dataframe for noting if each transmission was detected and by what (VR2 or vr100)
exp_df = as.data.frame(matrix(0, nrow = length(condition$datetime), ncol = 3))
colnames(exp_df) = c('datetime', 'v129577', 'vr100')
exp_df$datetime = condition$datetime
for(i in 1:length(all_data$datetime)){
for(r in 1:length(exp_df$datetime)){
if(all_data$datetime[i]-2 <= exp_df$datetime[r] & all_data$datetime[i]+2 >= exp_df$datetime[r]){
if(all_data$receiver[i] == 129577){
exp_df$v129577[r] = 1
}else if(all_data$receiver[i] == 'vr100'){
exp_df$vr100[r] = 1
}
}
}
}
detection_df_5 = melt(exp_df, id = c('datetime'))
model_data = merge(detection_df_5, condition[ ,c('tag_range', 'tag_depth', 'case_number', 'sub_case_number', 'dm', 'cpdi_type', 'datetime')], by = intersect(names(exp_df),names(condition[ ,c('tag_range', 'tag_depth', 'case_number', 'sub_case_number', 'dm', 'cpdi_type', 'datetime')])))
colnames(model_data)[c(2, 3)] = c('receiver', 'detected')
model_data$sub_case_number[model_data$sub_case_number == 0] = 1
model_data$sub_case_number = letters[model_data$sub_case_number]
model_data = model_data[model_data$receiver != 'vr100', ] # removing VR100 detections since we're not evaluation efficiency of VR100.
## Need to adjust experiment 4 as its currently one case for both receiver conditions.
model_data$sub_case_number[model_data$case_number == 4 & model_data$tag_range == 508] = 'b'
### Anna's helpful analysis ideas:
# 1. Create table Event (single event would be do, 2a, 150m, 15m)
event_table = model_data
# 2. Determining detection for predictions based on prediction type (1 if detection is predicted, 0 if not)
event_table$event = paste(event_table$case_number, event_table$sub_case_number, sep = "")
event_table$predicted_outcome = NA
event_table$predicted_outcome[event_table$cpdi_type == 'multipath_cpdi_predicted' ] = 0
event_table$predicted_outcome[event_table$cpdi_type == 'Control' ] = 1
event_table$predicted_outcome[event_table$cpdi_type == 'multipath_no_cpdi_predicted' ] = 1
# 3. Renaming variables for model fit
colnames(event_table)[which(colnames(event_table) == 'receiver')] = 'predicted_observed'
colnames(event_table)[which(colnames(event_table) == 'cpdi_type')] = 'cpdi_prediction'
event_table$cpdi_prediction = as.factor(event_table$cpdi_prediction)
colnames(event_table)[which(colnames(event_table) == 'event')] = 'experiment_analgoue'
event_table$experiment_analgoue = as.factor(event_table$experiment_analgoue)
#### Fitting a GLM to data
## Glm fit models whether transmission was detected as a function of our model's prediction
cpdi_glm.interaction = glm(detected ~  cpdi_prediction + experiment_analgoue + cpdi_prediction*experiment_analgoue, data = event_table, family = binomial)
summary(cpdi_glm.interaction)
table_3a = summary(cpdi_glm.interaction)$coefficients
write.csv(table_3a, file = file.path(results_dir, 'table_3a.csv'))
## removing non-significant interaction terms
cpdi_glm.no_interaction = glm(detected ~ cpdi_prediction + experiment_analgoue , data = event_table, family = binomial)
summary(cpdi_glm.no_interaction)
table_3b = summary(cpdi_glm.no_interaction)$coefficients
write.csv(table_3b, file = file.path(results_dir, 'table_3b.csv'))
### How many times did observations deviate from predictions?
## With control transmissions
sum(abs(event_table$predicted_outcome - event_table$detected))
length(event_table$predicted_outcome)
## Without control transmissions
sum(abs(event_table$predicted_outcome[event_table$cpdi_prediction != "Control"] - event_table$detected[event_table$cpdi_prediction != "Control"]))
length(event_table$predicted_outcome[event_table$cpdi_prediction != "Control"])
#### Model Diagnostics performed with Anna on 26 May 2017
library(MuMIn)
## Dredging model to determine most parsimonious model
options(na.action=na.fail)
dredge(cpdi_glm.no_interaction, extra="R^2")
resp<-event_table[, "detected"]
pred<-event_table[, c("cpdi_prediction", "experiment_analgoue")]
## Looking at model residuals
plot(cpdi_glm.no_interaction)
resp<-event_table[event_table$experiment_analgoue != '3b', "detected"]
pred<-event_table[event_table$experiment_analgoue != '3b', c("cpdi_prediction", "experiment_analgoue")]
## Which model term explains how much variation?
library(hier.part)
hier.part(resp, pred, family=binomial)
## Tukey Contrasts between experimental analogue groups
library('multcomp')
tukey_comparison = glht(cpdi_glm.no_interaction, mcp(experiment_analgoue="Tukey"))
plot(tukey_comparison)
class(event_table$experiment_analgoue)
event_table$experiment_analgoue = as.factor(event_table$experiment_analgoue)
event_table$cpdi_prediction = as.factor(event_table$cpdi_prediction)
## Visualizing differences in glm factors
library(visreg)
visreg(cpdi_glm.no_interaction)
anova(cpdi_glm.no_interaction)
dredge(cpdi_glm.interaction)
.8*64
## Comparing glm with interaction to glm without interaction term
anova(cpdi_glm.no_interaction, cpdi_glm.interaction, test="Chisq")
## Comparing best glm by stepwise addition of terms
anova(cpdi_glm.no_interaction, test="Chisq")
## What happens if we pull out control cases that we know failed?
cpdi_glm.no_interaction = glm(detected ~ cpdi_prediction + experiment_analgoue, data = subset(event_table, experiment_analgoue !="3a"), family = binomial)
dredge(cpdi_glm.no_interaction) # Best model still includes both terms
plot(cpdi_glm.no_interaction) # Checking out residuals
cpdi_glm.no_interaction = glm(detected ~ cpdi_prediction + experiment_analgoue, data = subset(event_table, experiment_analgoue !="2b"), family = binomial)
dredge(cpdi_glm.no_interaction)
summary(cpdi_glm.no_interaction) # Best model still includes both terms
visreg(cpdi_glm.no_interaction, scale="response") # Visualizing the differences in GLM factors
#### Analysis Cleanup
setwd(results_dir)
save.image(file = 'HIMB Multipath Tank Test Results.R')
###### Miscelanious Plots and Figures
#### Figure 2. Direct and First Multipath arrival comparision
### Setting up data repository and determining distance to calculate over
direct_arrival_times = c()
first_multipath_arrival_times = c()
calc_distance = 2000
simulated_sound_speed = 1530
### Running arrival simulation
for(dist in 1:calc_distance){
arrival_times = get_surf_paths(surface_to_tag_distance = 250,
surface_to_receiver_distance = 250,
tag_to_receiver_horizontal_distance = dist,
bottom_depth = 500,
speed_of_sound = simulated_sound_speed,
ave_max_detection_radius = 100000)
direct_arrival_times = c(direct_arrival_times, arrival_times[1])
first_multipath_arrival_times = c(first_multipath_arrival_times, arrival_times[2])
}
### Plot Set-up
setwd(figure_dir)
png('Figure 2 - Direct and multipath arrival times.png', width = 2000, height = 1000)
mar.default <- c(5,4,4,2) + 0.1
par(mar = mar.default + c(0, 4, 0, 0))
### Plotting
plot(y = direct_arrival_times, x = 1:calc_distance,
type = 'l',
cex = 2,
cex.lab = 2,
cex.axis = 2,
# main = 'Arrival Time of Direct and First Surface Reflected Multipath \n
#     Receiver Depth 250 m, Transmitter Depth = 250 m',
ylab = 'Arrival Time (s)', xlab = 'Distance Between Tag and Receiver (m)', font = 1)
lines(y = first_multipath_arrival_times, x = 1:calc_distance, type = 'l', lty = 4)
dev.off()
#### Figure 5. Comparing Deep and Shallow Water Detection Profiles
### Plot Set-up
png('Figure 5 - Comparing deep and shallow detection profiles.png', width = 2400, height = 1200)
mar.default <- c(5,4,4,2) + 0.1
par(mfrow = c(1, 2), mar = mar.default + c(0, 4, 0, 0))
### Plotting Deep Water Ranging Experiment Results
exp_1_data_to_plot = detection_df_1[which(detection_df_1$height_of_tag_off_bottom == 1 & detection_df_1$height_of_receiver_off_bottom == 1 & detection_df_1$direction == "In" & detection_df_1$day_night == "Day"), ]
plot((candidate_model_predictions_1$model_119$predicted_rates/60) ~ c(0:1000),
type = 'l',
xlim = c(0, 1000), xlab = "Distance Between Tag and Receiver (m)",
ylim = c(0, 1), ylab = "% of Transmissions Detected",
cex = 2,
cex.lab = 2,
cex.axis = 2,
main = "Deep Water Ranging Experiment")
points((exp_1_data_to_plot$detections/60) ~ exp_1_data_to_plot$distance, pch = 19, cex = 2)
## Adding AMDR to plot
points(x = levels(candidate_model_summary_1$ave_max_distance[1])[candidate_model_summary_1$ave_max_distance[1]], y = .05, pch = 8, cex = 2)
text(x = as.numeric(levels(candidate_model_summary_1$ave_max_distance[1])[candidate_model_summary_1$ave_max_distance[1]]) +50, y = .075, labels = paste('AMDR \n', max_distance-1, 'm'), col = 'black', cex = 1.5)
## Adding CPDI to plot
if(levels(candidate_model_summary_1$cpdi_extent)[candidate_model_summary_1$cpdi_extent][3] != 0){
points(x = as.numeric(levels(candidate_model_summary_1$cpdi_extent)[candidate_model_summary_1$cpdi_extent])[3], y = (candidate_model_predictions_1$model_119$predicted_rates[as.numeric(levels(candidate_model_summary_1$cpdi_extent)[candidate_model_summary_1$cpdi_extent])[3]] / 60), pch = 8, cex = 2)
text(x = levels(candidate_model_summary_1$cpdi_extent)[candidate_model_summary_1$cpdi_extent][3], y = .5, labels = paste('CPDI Extent \n ', levels(candidate_model_summary_1$cpdi_extent)[candidate_model_summary_1$cpdi_extent][3], 'm'), cex = 1.5)
}
### Plotting Shallow Water Ranging Experiment Results
exp_2_data_to_plot = detection_df_2[which(detection_df_2$height_of_receiver_off_bottom == 1 & detection_df_2$direction == "in" & detection_df_2$day_night == "day"), ]
plot((candidate_model_predictions_2$model_123$predicted_rates/60) ~ c(0:1200),
type = 'l',
xlim = c(0, 1200), xlab = "Distance Between Tag and Receiver (m)",
ylim = c(0, 1), ylab = "% of Transmissions Detected",
cex = 2,
cex.lab = 2,
cex.axis = 2,
main = "Shallow Water Ranging Experiment")
points((exp_2_data_to_plot$detections/60) ~ exp_2_data_to_plot$distance, pch = 19, cex = 2)
## Adding AMDR to plot
points(x = levels(candidate_model_summary_2$ave_max_distance[1])[candidate_model_summary_2$ave_max_distance[1]], y = .05, pch = 8, cex = 2)
text(x = as.numeric(levels(candidate_model_summary_2$ave_max_distance[1])[candidate_model_summary_2$ave_max_distance[1]]) + 75, y = .075, labels = paste('AMDR \n', max_distance-1, 'm'), col = 'black', cex = 2)
dev.off()
#### Figure 6. Comparing detections and pings
### Converting data classes to numeric for ggplot
metadata_df$pings = as.number(metadata_df$pings)
metadata_df$detections = as.number(metadata_df$detections)
### Creating a dataframe just for plotting
meta_for_plot = as.data.frame(rbind(cbind("rec_50m", 'pings / 8', mean(metadata_df$pings[metadata_df$receiver == "receiver_50m"]) / 8), cbind("rec_50m", 'detections', mean(metadata_df$detections[metadata_df$receiver == "receiver_50m"])),
cbind("rec_212m", 'pings / 8', mean(metadata_df$pings[metadata_df$receiver == "receiver_212m"]) / 8), cbind("rec_212m", 'detections', mean(metadata_df$detections[metadata_df$receiver == "receiver_212m"]))))
colnames(meta_for_plot) = c('receiver', 'Metric', 'Detected')
meta_for_plot$Detected = as.number(meta_for_plot$Detected)
### Plotting Figure
setwd(figure_dir)
png('exp_3_pings_vs_detections.png', height = 1800, width = 1800)
(ggplot(meta_for_plot, aes(factor(receiver), Detected, fill = Metric)) +
geom_bar(stat = "identity", position = "dodge") +
scale_fill_grey(start = 0, end = .7) + theme_bw())
dev.off()
setwd(results_dir)
###### Script Cleanup ----
save.image('completed_script.R')
# load(file.path(results_dir, 'completed_script.R'))
run_time = proc.time() - script_timer
send_push(user = 'uGEHvA4hr37tsrCCtpSv4sUUxVuTqN', message = paste("CPDI Analysis Completed in", round(run_time[3]), 'seconds!'))
