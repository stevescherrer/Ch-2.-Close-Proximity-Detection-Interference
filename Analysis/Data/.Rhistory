'hourly_detections_total' = c(57, 102, 138, 165, 186, 200, 210, 216, 218, 218, 215, 211, 205, 198, 191, 183, 175, 166),
stringsAsFactors = FALSE
)
expected_detections$hourly_detections_per_tag = expected_detections$hourly_detections_total / expected_detections$n_tags
####### COMPONENT 1: Deep Water Range Test ----
#### Loading In and Cleaning Data Files ----
setwd(data_dir)
### Loading Receiver Data
receiver_data = load_receiver(filename = 'DEPLOYMENT_RECOVERY_LOG.csv')
# dim(receiver_data)
# 217  28
### Loading VUE data
vue_data = load_vemco(filename = 'Range_Test_June_2014_All_Receivers.csv', format = '%m/%d/%y %H:%M')
#  dim(vue_data)
# 130284     10
### Importing Windspeed Data from from NOAA Honolulu station Station ID 1612340
# http://www.ndbc.noaa.gov/view_text_file.php?filename=oouh1h2014.txt.gz&dir=data/historical/stdmet/
# parent: http://www.ndbc.noaa.gov/station_history.php?station=oouh1
# Data dates range between dates 2014-01-01 00:00:00 and 2014-12-31 23:54:00
# with the following format:
# YY  MM DD hh mm WDIR WSPD GST  WVHT   DPD   APD MWD   PRES  ATMP  WTMP  DEWP  VIS  TIDE
# with the following units:
# yr  mo dy hr mn degT m/s  m/s     m   sec   sec degT   hPa  degC  degC  degC   mi    ft
wind_data = as.data.frame(read.table("oouh1h2014.txt"), header = TRUE, sep = " ")
# dim(wind_data)
# 85864    18
colnames(wind_data) = c("YY",  "MM", "DD", "hh", "mm", "WDIR", "WSPD", "GST",  "WVHT",   "DPD",   "APD", "MWD",   "PRES",  "ATMP",  "WTMP",  "DEWP",  "VIS",  "TIDE")
### Convert dates and times to POSIXct format. (Station data time is in local (UTC) time by default)
wind_data$datetime = as.POSIXct(paste(wind_data$YY, "-", wind_data$MM, "-", wind_data$DD, " ", wind_data$hh, ":", wind_data$mm, sep = ""), format = "%Y-%m-%d %H:%M", tz = "GMT")
### Convert datetime to HST
wind_data$datetime = strftime(wind_data$datetime, format = "%Y-%m-%d %H:%M")
wind_data$hourly = strftime(wind_data$datetime, format = "%Y-%m-%d %H")
### Grouping windspeed data into hourly means (mean_wspd)
wind_data_grouped = group_by(wind_data, hourly)
wspd_by_hour = summarize(wind_data_grouped, mean_wspd = mean(WSPD))
wspd_by_hour$hourly = as.POSIXct(wspd_by_hour$hourly, format = "%Y-%m-%d %H")
### Grouping windgust data into hourly means
gst_by_hour = summarize(wind_data_grouped, mean_gst = mean(GST))
gst_by_hour$hourly = as.POSIXct(gst_by_hour$hourly, format = "%Y-%m-%d %H")
### Importing tide data from: NOAA Honolulu station, accessed 28 OCT 2015
# http://tidesandcurrents.noaa.gov/waterlevels.html?id=1612340&units=standard&bdate=20110930&edate=20100930&timezone=LST&datum=MLLW&interval=h&action=## Meta data available here:
# Data accessed for dates ranging between 2013-09-30 00:00:00 HST and 2014-09-30 13:00:00 HST
# Data is already in HST
tide_data = read.csv('noaa tide data 2013-2014.csv')
# dim(tide_data)
# 8774    5
colnames(tide_data) = c("hour_bin", "water_level", 'sigma', 'I', "L")
tide_data$hour_bin = as.POSIXct(tide_data$hour_bin, format = "%Y-%m-%d %H:%M")
### Determining if tide was going in or out.
## First assume all data is headed in
tide_data$direction = "In"
## Then loop through data. If current water level is less than previous water level, tide is going out.
for(i in 2:length(tide_data$direction)){
if(tide_data$water_level[i-1] > tide_data$water_level[i]){
tide_data$direction[i] = "Out"
}
}
tide_data$direction = as.factor(tide_data$direction)
### Importing Tag Deployment Meta Data File
tag_meta_data = read.csv('Range Test June 2014 - Tag Meta Data Locations and Depth.csv')
# dim(tag_meta_data)
# 12  9
### Converting tag_meta_data Lat Lons from degree minutes to decimal degrees
tag_meta_data$lat = convert_lat_lon(tag_meta_data$lat_deg, tag_meta_data$lat_min)
tag_meta_data$lon = convert_lat_lon(tag_meta_data$lon_deg, tag_meta_data$lon_min)
### Determining distance of tag from receiver string using lon and lat waypoints from gps
for (i in 1:length(tag_meta_data$distance)){
tag_meta_data$distance[i] = round(1000*(lldist(point1 = c(tag_meta_data$lon[i],
tag_meta_data$lat[i]),
point2 = c(receiver_data$lon[receiver_data$station_name == 'Range Test - June 2014 - Diamond Head 1m'][1],
receiver_data$lat[receiver_data$station_name == 'Range Test - June 2014 - Diamond Head 1m'][1]))))
}
unique(tag_meta_data$distance)
# 0 199 399 578 766 959
### Removing any other receivers in the database
receiver_1m = 123736 # serial number of receiver in 1 m depth
receiver_30m = 123732 # serial number of receiver in 30 m depth
vue_data = vue_data[which(vue_data$receiver %in% c(receiver_1m, receiver_30m)), ]
### Removing detections prior to experiment (occurred durring experiment set up on boat) and determining an end to the experiment.
start_date = as.POSIXct('2014-06-07 8:00:00', tz = "HST")
# "2014-06-07 08:00:00 HST"
end_date = as.POSIXct("2014-06-26 05:00:00", format = "%Y-%m-%d %H:%M:%S")
# "2014-06-26 05:00:00 HST"
vue_data = vue_data[which(vue_data$datetime >= start_date & vue_data$datetime < end_date), ]
### Rounding off of final partial hour to account for transmissions received while gear was recovered
vue_data = vue_data[which(vue_data$datetime >= ceiling_date(min(vue_data$datetime), unit = 'hour') & vue_data$datetime < floor_date(max(vue_data$datetime), unit = 'hour')), ]
range(vue_data$datetime)
# "2014-06-07 09:00:00 HST" "2014-06-26 03:59:00 HST"
## How many total detections occurred durring the course of the experiment? (includes tags not part of range test)
detections_all = dim(vue_data)[1]
# 129622
### Removing tags not in experiment. This could be a tagged fish that swam by or a false detection
tags_0m    = c(18236, 18237)
tags_200m  = c(18238, 18239)
tags_400m  = c(18240, 18241)
tags_600m  = c(18242, 18243)
tags_800m  = c(18244, 18245)
tags_1000m = c(18246, 18247)
tag_ids = c(tags_0m, tags_200m, tags_400m, tags_600m, tags_800m, tags_1000m)
vue_data = vue_data[as.numeric(levels(vue_data$tag_id))[vue_data$tag_id]
%in% tag_ids, ]
## How many detections were from tags that were part of the experiment?
detections_experiment = dim(vue_data)[1]
# 128178
detections_experiment / detections_all * 100
# 98.88599 %
## How many detections were from tags that were not part of the experiment?
detections_other = detections_all - detections_experiment
# 1444
detections_other / detections_all * 100
# 1.114008
### Assigning Lon Lat positions to vue_data
vue_data = clean_vue_lat_lon(vue_data_df = vue_data,
receiver_data_df = receiver_data)
### Getting estimated distances between receivers and tags based on deployment coordinates
for (i in 1:length(tag_meta_data$lon)){
tag_meta_data$distance[i] = lldist(point1 = c(unique(vue_data$lon)[1],
unique(vue_data$lat)[1]),
point2 = c((tag_meta_data$lon)[i],
(tag_meta_data$lat)[i])) *
1000 # m/km
}
round(unique(tag_meta_data$distance))
# 0 199 399 578 766 959
#### Hourly Detection Data Analysis ----
### Separating data by tag, receiver, and hour bin
## First assign each datum to an date and hour bin
vue_data$hour_bin = floor_date(vue_data$datetime, unit = "hour")
## Then loop through combinations of date/hour, tag id, and receiver to get the number of detections from a tag at a receiver each hour
detection_df_1 = data.frame()
registerDoParallel(cores = n_cores)
detection_df_1 = foreach(b = c(1:length(unique(vue_data$hour_bin))), .combine = rbind) %:%
foreach(i = c(1:length(unique(vue_data$tag_id))), .combine = rbind) %:%
foreach(r = c(1:length(unique(vue_data$receiver))), .combine = rbind) %dopar%{
filtered = filter(vue_data, hour_bin == unique(vue_data$hour_bin)[b],
tag_id == unique(vue_data$tag_id)[i],
receiver == unique(vue_data$receiver)[r])
write_line = cbind(as.character(unique(vue_data$hour_bin))[b],
as.character(unique(vue_data$tag_id))[i],
as.character(unique(vue_data$receiver))[r],
dim(filtered)[1])
return(write_line)
}
## Cleaning detection_df_1
detection_df_1 = as.data.frame(detection_df_1)
colnames(detection_df_1) = c('hour_bin', 'tag_id', 'receiver', 'detections')
detection_df_1$detections = as.numeric(as.character(detection_df_1$detections))
# dim(detection_df_1)
# 10824     4
dim(detection_df_1)
??uniqueN
library('data.table')
detections_per_hour = aggregate(detection_df_1$tag_id, by = list(detection_df_1$hour_bin), FUN = uniqueN)
detections_per_hour
detections_per_hour = aggregate(detection_df_1$tag_id[detection_df_1$detections != 0], by = list(detection_df_1$hour_bin[detection_df_1$detections != 0]), FUN = uniqueN)
detections_per_hour
detection_df_1 = merge(detection_df_1, tag_meta_data,
by.x = colnames(detection_df_1) == 'tag_id',
by.y = colnames(tag_meta_data) == 'tag_id')
detection_df_1$distance = detection_df_1$distance
detection_df_1$height_off_bottom = as.factor(detection_df_1$height_off_bottom)
detection_df_1$recovery_rate = detection_df_1$detections / 60
detection_df_1$day = as.factor(strftime(detection_df_1$hour_bin, format = "%Y-%m-%d"))
detection_df_1$time = as.factor(strftime(detection_df_1$hour_bin, format = "%H:%M:%S"))
colnames(detection_df_1)[colnames(detection_df_1) == 'height_off_bottom'] = "height_of_tag_off_bottom"
detection_df_1$hour_bin = as.POSIXct(detection_df_1$hour_bin, format = "%Y-%m-%d %H:%M:%S")
detection_df_1$tags_per_hour = NA
tags_per_hour = aggregate(detection_df_1$tag_id[detection_df_1$detections != 0], by = list(detection_df_1$hour_bin[detection_df_1$detections != 0]), FUN = uniqueN)
detection_df_1$hour_bin
tags_per_hour
detection_df_1 = merge(detection_df_1, tags_per_hour, by.x = detection_df_1$hour_bin, by.y = tags_per_hour$Group.1)
detection_df_1 = merge(detection_df_1, tags_per_hour, by.x = colnames(detection_df_1) == "hour_bin", by.y = colnames(tags_per_hour) == 'Group.1')
detection_df_1 = merge(detection_df_1, tags_per_hour, by.x = colnames(detection_df_1) == "hour_bin", by.y = colnames(tags_per_hour) == 'hour_bin')
colnames(tags_per_hour) = c("hour_bin", "tags_per_hour")
detection_df_1 = merge(detection_df_1, tags_per_hour, by.x = colnames(detection_df_1) == "hour_bin", by.y = colnames(tags_per_hour) == 'hour_bin')
detection_df_1$tags_per_hour.y
detection_df_1 = data.frame()
registerDoParallel(cores = n_cores)
detection_df_1 = foreach(b = c(1:length(unique(vue_data$hour_bin))), .combine = rbind) %:%
foreach(i = c(1:length(unique(vue_data$tag_id))), .combine = rbind) %:%
foreach(r = c(1:length(unique(vue_data$receiver))), .combine = rbind) %dopar%{
filtered = filter(vue_data, hour_bin == unique(vue_data$hour_bin)[b],
tag_id == unique(vue_data$tag_id)[i],
receiver == unique(vue_data$receiver)[r])
write_line = cbind(as.character(unique(vue_data$hour_bin))[b],
as.character(unique(vue_data$tag_id))[i],
as.character(unique(vue_data$receiver))[r],
dim(filtered)[1])
return(write_line)
}
detection_df_1 = as.data.frame(detection_df_1)
colnames(detection_df_1) = c('hour_bin', 'tag_id', 'receiver', 'detections')
detection_df_1$detections = as.numeric(as.character(detection_df_1$detections))
dim(detection_df_1)
detection_df_1 = merge(detection_df_1, tag_meta_data,
by.x = colnames(detection_df_1) == 'tag_id',
by.y = colnames(tag_meta_data) == 'tag_id')
detection_df_1$distance = detection_df_1$distance
detection_df_1$height_off_bottom = as.factor(detection_df_1$height_off_bottom)
detection_df_1$recovery_rate = detection_df_1$detections / 60
detection_df_1$day = as.factor(strftime(detection_df_1$hour_bin, format = "%Y-%m-%d"))
detection_df_1$time = as.factor(strftime(detection_df_1$hour_bin, format = "%H:%M:%S"))
colnames(detection_df_1)[colnames(detection_df_1) == 'height_off_bottom'] = "height_of_tag_off_bottom"
detection_df_1$hour_bin = as.POSIXct(detection_df_1$hour_bin, format = "%Y-%m-%d %H:%M:%S")
## Calculating the number of unique tags detected during each hour bin
tags_per_hour = aggregate(detection_df_1$tag_id[detection_df_1$detections != 0], by = list(detection_df_1$hour_bin[detection_df_1$detections != 0]), FUN = uniqueN)
colnames(tags_per_hour) = c("hour_bin", "tags_per_hour")
detection_df_1 = merge(detection_df_1, tags_per_hour, by.x = colnames(detection_df_1) == "hour_bin", by.y = colnames(tags_per_hour) == 'hour_bin')
detection_df_1$tags_per_hour
detection_df_1$day_night = 'Night'
for(i in 1:length(detection_df_1$hour_bin)){
if(hour(detection_df_1$hour_bin[i]) < 18 & hour(detection_df_1$hour_bin[i]) > 6){
detection_df_1$day_night[i] = 'Day'
}
}
detection_df_1$day_night = as.factor(detection_df_1$day_night)
### Assigning receiver height
detection_df_1$height_of_receiver_off_bottom = NULL
detection_df_1$height_of_receiver_off_bottom[detection_df_1$receiver == receiver_1m] = '1'
detection_df_1$height_of_receiver_off_bottom[detection_df_1$receiver == receiver_30m] = '30'
detection_df_1$height_of_receiver_off_bottom = as.factor(detection_df_1$height_of_receiver_off_bottom)
### Determining recovery rate based on the number of detections logged and an average of 60 transmissions per tag per hour
detection_df_1$recovery_rate = detection_df_1$detections / 60
# dim(detection_df_1)
# 10824    26
#### Statistical Analysis - Modeling Detection Probability ----
dim(detection_df_1)
### Setting Model Parameters
alpha = 0.05
transmissions_per_hour = 60
detection_threshold = (alpha * transmissions_per_hour)
# 3
expected_detections$n_tags == detection_df_1$tags_per_hour
detection_df_1$tags_per_hour
head(detection_df_1$tags_per_hour)
head(expected_detections$hourly_detections_per_tag[expected_detections$n_tags == detection_df_1$tags_per_hour])
head(expected_detections$hourly_detections_per_tag[expected_detections$n_tags %in% detection_df_1$tags_per_hour]
# dim(detection_df_1))
)
?apply
apply(detection_df_1$tags_per_hour, function(x), which(x), %in% expected_detections$n_tags)
apply(detection_df_1$tags_per_hour, function(x), which(x) %in% expected_detections$n_tags)
apply(detection_df_1$tags_per_hour, function(x), which(x %in% expected_detections$n_tags))
apply(detection_df_1$tags_per_hour, function(x) which(x %in% expected_detections$n_tags))
apply(detection_df_1$tags_per_hour, FUN(x) which(x %in% expected_detections$n_tags))
apply(detection_df_1$tags_per_hour, FUN(x), which(x %in% expected_detections$n_tags))
apply(x = detection_df_1$tags_per_hour, FUN(x), which(x %in% expected_detections$n_tags))
which(detection_df_1$tags_per_hour[i] %in% expected_detections$n_tags)
which(detection_df_1$tags_per_hour[2] %in% expected_detections$n_tags)
which(expected_detections$n_tags %in% detection_df_1$tags_per_hour[2])
which(expected_detections$n_tags %in% detection_df_1$tags_per_hour[760])
detection_df_1$recovery_rate = NA
for(i in 1:length(detection_df_1$tags_per_hour)){
detection_df_1$recovery_rate = detection_df_1$detections / expected_detections$hourly_detections_per_tag[which(expected_detections$n_tags %in% detection_df_1$tags_per_hour[760])]
}
for(i in 1:length(detection_df_1$tags_per_hour)){
detection_df_1$recovery_rate[i] = detection_df_1$detections / expected_detections$hourly_detections_per_tag[which(expected_detections$n_tags %in% detection_df_1$tags_per_hour[i])]
}
warnings()
unique(detection_df_1$recovery_rate[i])
unique(detection_df_1$recovery_rate)
for(i in 1:length(detection_df_1$tags_per_hour)){
detection_df_1$recovery_rate[i] = detection_df_1$detections[i] / expected_detections$hourly_detections_per_tag[which(expected_detections$n_tags %in% detection_df_1$tags_per_hour[i])]
}
unique(detection_df_1$recovery_rate)
range(detection_df_1$recovery_rate)
unique(detection_df_1$distance[detection_df_1$recovery_rate > 1])
unique(detection_df_1$distance[detection_df_1$recovery_rate > 2])
range(detection_df_1$detections)
aggregate(detection_df_1$detections, By = list(detection_df_1$hour_bin), FUN = sum)
aggregate(detection_df_1$detections, by = list(detection_df_1$hour_bin), FUN = sum)
aggregate(detection_df_1$detections, by = list(detection_df_1$hour_bin), FUN = sum)$'x'
range(aggregate(detection_df_1$detections, by = list(detection_df_1$hour_bin), FUN = sum)$'x')
mean(aggregate(detection_df_1$detections, by = list(detection_df_1$hour_bin), FUN = sum)$'x')
setwd(data_dir)
### Importing VR100 data
vr100_raw = read.csv(file.path(data_dir, 'VR100_10320_D2016.07.15T20.49.23.csv'))
### Importing VR2 data from VUE
vr2 = load_vemco(file.path(data_dir, 'VUE_Export_CPDI_Tank_Test.csv'))
### Importing meta data regarding when transmissions were sent recorded from Brendan's laptop durring experiment
condStoreDM = read.csv(paste(data_dir, 'condStoreDM.csv', sep = ""), header = FALSE)
condStoreDO = read.csv(paste(data_dir, 'condStoreDO.csv', sep = ""), header = FALSE)
### Creating vr100 datafame for manipulation
vr100 = vr100_raw
vr100$datetime = as.POSIXct(paste(vr100$Date, vr100$Time, sep = " "), format = "%Y-%m-%d %H:%M:%S", tz = "GMT")
attr(vr100$datetime, "tzone") <- "HST"
colnames(vr100) = c("date", "time", "chan", "freq", "type", "code_space", "tag_id", "serial_number", "data1", "units1", "slope1", "init1", "data2", "units2", "slope2", "int2", "signal_db", "gain_mode", "gain_db", "lat", "lon", "comment", "datetime")
# creating vr2 dataframe for manipulation
vr2$datetime = as.POSIXct(vr2$datetime, tz = "GMT")
attr(vr2$datetime, "tzone") <- "GMT"
vr2 = vr2[vr2$datetime >= as.POSIXct("2016-07-12 16:30:00"), ]
### Creating dataframes for direct and multipath conditions
colnames(condStoreDO) = c('pluse_train_time', 'tag_range', 'tag_depth', 'relative_arrival_time_0','case_number', 'sub_case_number')
colnames(condStoreDM)[1:3] = c('pluse_train_time', 'tag_range', 'tag_depth')
colnames(condStoreDM)[4:23] = paste('relative_arrival_time_', 0:19, sep = "")
colnames(condStoreDM)[24:25] = c('case_number', 'sub_case_number')
condStoreDO$dm = 'direct only' # designates whether multipath or not
condStoreDM$dm = 'multipath' # designates whether multipath or not
### Predicting whether multipaths produced CPDI effects
## DO conditions only have a direct signal, all should be detected by receivers. thus they are marked as control
condStoreDO$cpdi_type = 'Control'
## To determine if multipath signals cause CPDI, we compare the relative arrival times of the multipath signals to the blanking interval (0.260 seconds).
condStoreDM$cpdi_type = 'multipath_no_cpdi_predicted'
for(i in 1:dim(condStoreDM)[1]){
if(any(condStoreDM[i,4:23] != 0 & condStoreDM[i,4:23] > 0.260)){
condStoreDM$cpdi_type[i] = 'multipath_cpdi_predicted'
}
}
### Combining direct and multipath condition dataframes into a single dataframe
## condStoreDO to do this, condStoreDO needs to be padded out to be same size as DM. This meens adding 20 additional columns
condStoreDO = cbind(condStoreDO[ ,1:4], matrix(data = NA, nrow = dim(condStoreDO)[1], ncol = 19), condStoreDO[ ,5:8])
colnames(condStoreDO)[5:23] = paste('relative_arrival_time_', 1:19, sep = "")
## Combining dataframes
condition = data.frame(rbind(condStoreDO, condStoreDM)) # Combining into condition dataframe
## Converting matlab date nubmers to POSIX datetime objects
condition$datetime = datenum2posix(condition$pluse_train_time)
### Ordering dataframes by increasing time of detection
condition = condition[order(condition$datetime), ] # sorting by time
vr2 = vr2[sort.list(x = vr2$datetime, decreasing = FALSE), ]
vr100 = vr100[sort.list(x = vr100$datetime, decreasing = FALSE), ]
rownames(vr100) = NULL
rownames(vr2) = NULL
### Converting vr2$receiver and vr2$tag_id to numeric
vr2$receiver = as.numeric(levels(vr2$receiver)[vr2$receiver])
vr2$tag_id = as.numeric(levels(vr2$tag_id)[vr2$tag_id])
vr2$datetime
#### Loading In and Cleaning Data Files ----
setwd(data_dir)
### Loading Receiver Data
receiver_data = load_receiver(filename = 'DEPLOYMENT_RECOVERY_LOG.csv')
# dim(receiver_data)
# 217  28
### Loading VUE data
vue_data = load_vemco('sand_island_range_test_nov_dec_2014.csv')
# dim(vue_data)
# 426181     10
### Importing Windspeed Data from from NOAA Honolulu station Station ID 1612340
# http://www.ndbc.noaa.gov/view_text_file.php?filename=oouh1h2015.txt.gz&dir=data/historical/stdmet/
# parent: http://www.ndbc.noaa.gov/station_history.php?station=oouh1
# Data dates range between dates 2014-01-01 00:00:00 and 2014-12-31 23:54:00
# with the following format:
# YY  MM DD hh mm WDIR WSPD GST  WVHT   DPD   APD MWD   PRES  ATMP  WTMP  DEWP  VIS  TIDE
# with the following units:
# yr  mo dy hr mn degT m/s  m/s     m   sec   sec degT   hPa  degC  degC  degC   mi    ft
wind_data = as.data.frame(read.table("oouh1h2014.txt"), header = TRUE, sep = " ")
#  dim(wind_data)
# 85864    18
colnames(wind_data) = c("YY",  "MM", "DD", "hh", "mm", "WDIR", "WSPD", "GST",  "WVHT",   "DPD",   "APD", "MWD",   "PRES",  "ATMP",  "WTMP",  "DEWP",  "VIS",  "TIDE")
### Convert dates and times to POSIXct format. (Station data time is in local (UTC) time by default)
wind_data$datetime = as.POSIXct(paste(wind_data$YY, "-", wind_data$MM, "-", wind_data$DD, " ", wind_data$hh, ":", wind_data$mm, sep = ""), format = "%Y-%m-%d %H:%M", tz = "GMT")
### Convert datetime to HST
wind_data$datetime = strftime(wind_data$datetime, format = "%Y-%m-%d %H:%M")
wind_data$hourly = strftime(wind_data$datetime, format = "%Y-%m-%d %H")
### Grouping windspeed data into hourly means (mean_wspd)
wind_data_grouped = group_by(wind_data, hourly)
wspd_by_hour = summarize(wind_data_grouped, mean_wspd = mean(WSPD))
wspd_by_hour$hourly = as.POSIXct(wspd_by_hour$hourly, format = "%Y-%m-%d %H")
### Grouping windgust data into hourly means
gst_by_hour = summarize(wind_data_grouped, mean_gst = mean(GST))
gst_by_hour$hourly = as.POSIXct(gst_by_hour$hourly, format = "%Y-%m-%d %H")
### Importing tide data from: NOAA Honolulu station, accessed 27 Jan 2017
# http://tidesandcurrents.noaa.gov/waterlevels.html?id=1612340&units=standard&bdate=20110930&edate=20100930&timezone=LST&datum=MLLW&interval=h&action=## Meta data available here:
# Data accessed for dates ranging between 2014-09-30 00:00:00 HST and 2015-09-30 13:00:00 HST
# Data is already in HST
tide_data = read.csv('noaa tide data 214-2015.csv')
# dim(tide_data)
#  8784    5
colnames(tide_data) = c("hour_bin", "water_level", 'sigma', 'I', "L")
tide_data$hour_bin = as.POSIXct(tide_data$hour_bin, format = "%Y-%m-%d %H:%M")
### Determining if tide was going in or out.
## First assume all data is headed in
tide_data$direction = "in"
## Then loop through data. If current water level is less than previous water level, tide is going out.
for(i in 2:length(tide_data$direction)){
if(tide_data$water_level[i-1] > tide_data$water_level[i]){
tide_data$direction[i] = "out"
}
}
tide_data$direction = as.factor(tide_data$direction)
### Importing Tag Deployment Meta Data File
tag_meta_data = read.csv('Range Test Nov 2014 - Tag Meta Data Locations and Depth.csv')
# 18  9
### Converting Lat Lons from degree minutes to decimal degrees
tag_meta_data$lat = convert_lat_lon(tag_meta_data$lat_deg, tag_meta_data$lat_min)
tag_meta_data$lon = convert_lat_lon(tag_meta_data$lon_deg, tag_meta_data$lon_min)
### Determining distance of tag from receiver string using lon and lat waypoints from gps
for (i in 1:length(tag_meta_data$distance)){
tag_meta_data$distance[i] = round(1000*(lldist(point1 = c(tag_meta_data$lon[i],
tag_meta_data$lat[i]),
point2 = c(receiver_data$lon[receiver_data$station_name == 'Range Test - Nov 2014 - Sand Island 1m'][1],
receiver_data$lat[receiver_data$station_name == 'Range Test - Nov 2014 - Sand Island 1m'][1]))))
}
unique(tag_meta_data$distance)
# 0   75  150  300  600 1200
### Removing detections prior to experiment (occurred durring experiment set up on boat) and determining an end to the experiment.
start_date = as.POSIXct("2014-11-21 10:15:00 HST")
end_date = as.POSIXct("2014-12-02 07:22:00 HST")
vue_data = vue_data[which(vue_data$datetime >= start_date & vue_data$datetime < end_date), ]
### Rounding off of final partial hour to account for transmissions received while gear was recovered
vue_data = vue_data[which(vue_data$datetime >= ceiling_date(min(vue_data$datetime), unit = 'hour') & vue_data$datetime < floor_date(max(vue_data$datetime), unit = 'hour')), ]
range(vue_data$datetime)
# "2015-03-17 19:00:23 HST" "2015-03-25 10:58:53 HST"
# dim(vue_data)
# 423384     10
### Grouping receivers by height condition (m of sea floor)
rec_1m  = c(103911, 110298, 110308)
rec_7.5m = c(102200, 123736, 123732)
rec_15m = c(123733, 104543, 123734)
## How many total detections occurred durring the course of the experiment?
detections_all = dim(vue_data)[1]
# 423384
### Removing tags not in experiment. This could be a tagged fish that swam by or a false detection
tags_0m    = c(18255, 18257, 18256)
tags_75m  = c(18260, 18273, 18270)
tags_150m  = c(18265, 18259, 18269)
tags_300m  = c(18262, 18258, 18271)
tags_600m  = c(18261, 18275, 18274)
tags_1200m = c(18272, 18268, 18263)
tag_ids = c(tags_0m, tags_75m, tags_150m, tags_300m, tags_600m, tags_1200m)
vue_data = vue_data[as.numeric(levels(vue_data$tag_id))[vue_data$tag_id]
%in% tag_ids, ]
## How many detections were from tags that were part of the experiment?
detections_experiment = dim(vue_data)[1]
# Total detections of experimental tags = 421342
detections_experiment.percent = detections_experiment / detections_all * 100
# 99.5177 %
## How many detections were from tags that were not part of the experiment?
detections_other = detections_all - detections_experiment
# Total detections from other tags = 2042
detections_other.percent = detections_other / detections_all * 100
# 0.4823045 %
## Assigning Lon Lat positions to detections
vue_data = clean_vue_lat_lon(vue_data_df = vue_data,
receiver_data_df = receiver_data)
## Getting estimated distances between receivers and tags based on deployment coordinates
for (i in 1:length(tag_meta_data$lon)){
tag_meta_data$distance[i] = lldist(point1 = c(unique(vue_data$lon)[1],
unique(vue_data$lat)[1]),
point2 = c((tag_meta_data$lon)[i],
(tag_meta_data$lat)[i])) *
1000 # m/km
}
round(unique(tag_meta_data$distance))
# Distances are: 0   75  150  300  600 1200
#### Hourly Detection Data Analysis ----
### Binning data by tag, receiver, and hour bin
## First assign each datum to an date and hour bin
vue_data$hour_bin = floor_date(vue_data$datetime, unit = "hour")
## Then loop through combinations of date/hour, tag id, and receiver to get the number of detections from a tag at a receiver each hour
detection_df_2 = data.frame()
registerDoParallel(cores = n_cores)
detection_df_2 = foreach(b = c(1:length(unique(vue_data$hour_bin))), .combine = rbind) %:%
foreach(i = c(1:length(unique(vue_data$tag_id))), .combine = rbind) %:%
foreach(r = c(1:length(unique(vue_data$receiver))), .combine = rbind) %dopar%{
filtered = filter(vue_data, hour_bin == unique(vue_data$hour_bin)[b],
tag_id == unique(vue_data$tag_id)[i],
receiver == unique(vue_data$receiver)[r])
write_line = cbind(as.character(unique(vue_data$hour_bin))[b],
as.character(unique(vue_data$tag_id))[i],
as.character(unique(vue_data$receiver))[r],
dim(filtered)[1])
return(write_line)
}
## Cleaning detection_df_2
detection_df_2 = as.data.frame(detection_df_2)
colnames(detection_df_2) = c('hour_bin', 'tag_id', 'receiver', 'detections')
# dim(detection_df_2)
# 32760     4
detection_df_2$detections = as.numeric(as.character(detection_df_2$detections))
detection_df_2$day = as.factor(strftime(detection_df_2$hour_bin, format = "%Y-%m-%d"))
detection_df_2$time = as.factor(strftime(detection_df_2$hour_bin, format = "%H:%M:%S"))
detection_df_2$height_of_tag_off_bottom = 7.5
detection_df_2$height_of_tag_off_bottom = as.factor(detection_df_2$height_of_tag_off_bottom)
detection_df_2$hour_bin = as.POSIXct(detection_df_2$hour_bin, format = "%Y-%m-%d %H:%M:%S")
### Combining detection dataframe with distance, bottom depth, height condition, lat, and lon tag_meta_data
detection_df_2 = merge(detection_df_2, tag_meta_data,
by.x = colnames(detection_df_2) == 'tag_id',
by.y = colnames(tag_meta_data) == 'tag_id')
## Combining detection data with wind speed, and wind gust data
detection_df_2 = merge(detection_df_2, wspd_by_hour,
by.x = colnames(detection_df_2) == 'hour_bin',
by.y = colnames(wspd_by_hour) == 'hourly')
detection_df_2 = merge(detection_df_2, gst_by_hour,
by.x = colnames(detection_df_2) == 'hour_bin',
by.y = colnames(gst_by_hour) == 'hourly')
detection_df_2 = merge(detection_df_2, tide_data,
by.x = colnames(detection_df_2) == 'hour_bin',
by.y = colnames(tide_data) == 'hour_bin')
detection_df_2$hour_bin = as.factor(detection_df_2$hour_bin)
### Assigning Receivers to a height condition (height of sea floor)
detection_df_2$height_of_receiver_off_bottom = NA
detection_df_2$height_of_receiver_off_bottom[which(detection_df_2$receiver %in% rec_1m)] = 1
detection_df_2$height_of_receiver_off_bottom[which(detection_df_2$receiver %in% rec_7.5m)] = 7.5
detection_df_2$height_of_receiver_off_bottom[which(detection_df_2$receiver %in% rec_15m)] = 15
detection_df_2$height_of_receiver_off_bottom = as.factor(detection_df_2$height_of_receiver_off_bottom)
### Assigning diurnal period to detections based around 12 hour time bins. Before 6am or after 6pm considered night, between 6am and 6pm considered day
detection_df_2$day_night = 'night'
for(i in 1:length(detection_df_2$hour_bin)){
if(hour(detection_df_2$hour_bin[i]) < 18 & hour(detection_df_2$hour_bin[i]) > 6){
detection_df_2$day_night[i] = 'day'
}
}
detection_df_2$day_night = as.factor(detection_df_2$day_night)
### Determining recovery rate based on the number of detections logged and an average of 60 transmissions per tag per hour
detection_df_2$recovery_rate = detection_df_2$detections / 60
# dim(detection_df_2)
# 32760    27
range(aggregate(detection_df_2$tag_id[detection_df_2$detections != 0], by = list(detection_df_2$hour_bin[detection_df_2$detections != 0]), FUN = uniqueN))
aggregate(detection_df_2$tag_id[detection_df_2$detections != 0], by = list(detection_df_2$hour_bin[detection_df_2$detections != 0]), FUN = uniqueN)
range(aggregate(detection_df_2$tag_id[detection_df_2$detections != 0], by = list(detection_df_2$hour_bin[detection_df_2$detections != 0]), FUN = uniqueN)$'x')
unique(detection_df_2$tag_id[detection_df_2$detections > 0])
unique(detection_df_2$distance[detection_df_2$detections > 0])
